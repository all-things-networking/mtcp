#include "mtp_ep.h"

#include <linux/tcp.h>

#include "tcp_in.h"
#include "tcp_out.h"
#include "timer.h"
#include "tcp_stream.h"
#include "fhash.h"
#include "debug.h"
#include "ip_out.h"
#include "tcp_util.h"
#include "socket.h"
#include "mtp_instr.h"
#include "mtp_net.h"

#define MAX(a, b) ((a)>(b)?(a):(b))
#define MIN(a, b) ((a)<(b)?(a):(b))
#define TCP_MAX_WINDOW 65535

// Intermediate output
typedef struct scratchpad_decl {
	uint8_t change_cwnd;
	uint8_t skip_ack_eps;
} scratchpad;


// Helper functions
/*----------------------------------------------------------------------------*/
static inline void EstimateRTT(mtcp_manager_t mtcp, tcp_stream *cur_stream, uint32_t mrtt)
{
	/* This function should be called for not retransmitted packets */
	/* TODO: determine tcp_rto_min */
#define TCP_RTO_MIN 0
	long m = mrtt;
	uint32_t tcp_rto_min = TCP_RTO_MIN;
	struct tcp_recv_vars *rcvvar = cur_stream->rcvvar;

	if (m == 0) {
		m = 1;
	}
	if (rcvvar->srtt != 0) {
		/* rtt = 7/8 rtt + 1/8 new */
		m -= (rcvvar->srtt >> 3);
		rcvvar->srtt += m;
		if (m < 0) {
			m = -m;
			m -= (rcvvar->mdev >> 2);
			if (m > 0) {
				m >>= 3;
			}
		} else {
			m -= (rcvvar->mdev >> 2);
		}
		rcvvar->mdev += m;
		if (rcvvar->mdev > rcvvar->mdev_max) {
			rcvvar->mdev_max = rcvvar->mdev;
			if (rcvvar->mdev_max > rcvvar->rttvar) {
				rcvvar->rttvar = rcvvar->mdev_max;
			}
		}
		if (TCP_SEQ_GT(cur_stream->mtp->send_una, rcvvar->rtt_seq)) {
			if (rcvvar->mdev_max < rcvvar->rttvar) {
				rcvvar->rttvar -= (rcvvar->rttvar - rcvvar->mdev_max) >> 2;
			}
			rcvvar->rtt_seq = cur_stream->mtp->send_next;
			rcvvar->mdev_max = tcp_rto_min;
		}
	} else {
		/* fresh measurement */
		rcvvar->srtt = m << 3;
		rcvvar->mdev = m << 1;
		rcvvar->mdev_max = rcvvar->rttvar = MAX(rcvvar->mdev, tcp_rto_min);
		rcvvar->rtt_seq = cur_stream->mtp->send_next;
	}

	TRACE_RTT("mrtt: %u (%uus), srtt: %u (%ums), mdev: %u, mdev_max: %u, "
			"rttvar: %u, rtt_seq: %u\n", mrtt, mrtt * TIME_TICK, 
			rcvvar->srtt, TS_TO_MSEC((rcvvar->srtt) >> 3), rcvvar->mdev, 
			rcvvar->mdev_max, rcvvar->rttvar, rcvvar->rtt_seq);
}


/***********************************************
 MTP Event Processors
 
 EPs are static and used only by MTP EP chains
 They have 1-to-1 mappings to mtp code
 They should be generated by the MTP compiler
 ***********************************************/
static inline void send_ep(mtcp_manager_t mtcp, uint32_t cur_ts, tcp_stream *cur_stream)
{
	struct tcp_send_vars *sndvar = cur_stream->sndvar;

    if (cur_stream->mtp->state != MTP_TCP_ESTABLISHED_ST) return;

	struct mtp_ctx *ctx = cur_stream->mtp;
	
	SBUF_LOCK(&sndvar->write_lock);
	if (!sndvar->sndbuf || sndvar->sndbuf->len == 0) {
        SBUF_UNLOCK(&sndvar->write_lock);
        return;
	}

	// MTP: maps to bytes_to_send
	int data_rest = ctx->send_una + sndvar->sndbuf->len - ctx->send_next;
	int window_avail = MIN(ctx->cwnd_size, ctx->last_rwnd_remote) - (ctx->send_next - ctx->send_una);
    int bytes_to_send = MIN(data_rest, window_avail);
	if (bytes_to_send <= 0) {
		SBUF_UNLOCK(&sndvar->write_lock);
        return;
	}

	// MTP: maps to packet blueprint creation
	
	mtp_bp* bp = GetFreeBP(cur_stream);
    
    memset(&(bp->hdr), 0, sizeof(struct mtp_bp_hdr) + sizeof(struct mtp_bp_options));

    bp->hdr.source = cur_stream->mtp->local_port;
    bp->hdr.dest = cur_stream->mtp->remote_port;
    bp->hdr.seq = htonl(ctx->send_next);
    bp->hdr.ack_seq = htonl(ctx->recv_next);

    bp->hdr.syn = FALSE;
    bp->hdr.ack = FALSE;

    // options to calculate data offset
   
    // MTP TODO: SACK? 
#if TCP_OPT_SACK_ENABLED
    printf("ERROR:SACK Not supported in MTP TCP\n");
#endif

    MTP_set_opt_nop(&(bp->opts.nop1));
    MTP_set_opt_nop(&(bp->opts.nop2));

    // MTP TODO: Timestamp
    MTP_set_opt_timestamp(&(bp->opts.timestamp),
                            htonl(cur_ts),
                            htonl(cur_stream->rcvvar->ts_recent));
    
   
    // MTP TODO: would the MTP program do the length 
    //           calculation itself?
    uint16_t optlen = MTP_CalculateOptionLength(bp);
    bp->hdr.doff = (MTP_HEADER_LEN + optlen) >> 2;

    // MTP TODO: wscale on local
	uint8_t wscale = ctx->wscale;
    uint32_t window32 = ctx->rwnd_size >> wscale;  
	// MTP TODO: fix this
    uint16_t advertised_window = (uint16_t)MIN(window32, TCP_MAX_WINDOW);
    bp->hdr.window = htons(advertised_window);

    // Payload
    // MTP TODO: fix snbuf
    uint8_t *data = sndvar->sndbuf->head - sndvar->sndbuf->head_seq + ctx->send_next;
    bp->payload.data = data;
    bp->payload.len = bytes_to_send;
    bp->payload.needs_segmentation = TRUE;
    bp->payload.seg_size = ctx->eff_SMSS;
    bp->payload.seg_rule_group_id = 1; 

    AddtoGenList(mtcp, cur_stream, cur_ts);	

	ctx->send_next += bytes_to_send;

	// MTP TODO: map to timer event with event input
	TimerStart(mtcp, cur_stream, cur_ts);

	return;
}

static inline void conn_ack_ep ( mtcp_manager_t mtcp, int32_t cur_ts, uint32_t ack_seq, 
        tcp_stream* cur_stream, scratchpad* scratch){

    if (cur_stream->mtp->state == MTP_TCP_SYNACK_SENT_ST &&
        ack_seq == cur_stream->mtp->init_seq + 1){
        cur_stream->mtp->state = MTP_TCP_ESTABLISHED_ST;
        cur_stream->mtp->send_una += 1;
        cur_stream->mtp->send_next = ack_seq;
        cur_stream->mtp->last_ack = ack_seq;

        if (cur_stream->mtp->cwnd_size == 1){
            cur_stream->mtp->cwnd_size = 2 * cur_stream->mtp->SMSS;
        }
        else {
            cur_stream->mtp->cwnd_size = cur_stream->mtp->SMSS;
        }
        scratch->skip_ack_eps = 1;
        TimerCancel(mtcp, cur_stream);

        // Raise an event to the listening socket
		struct mtp_listen_ctx *listen_ctx = 
			(struct mtp_listen_ctx *)ListenerHTSearch(mtcp->listeners, &cur_stream->sport);
		if (listen_ctx->socket && (listen_ctx->socket->epoll & MTCP_EPOLLIN)) {
			AddEpollEvent(mtcp->ep, MTCP_EVENT_QUEUE, listen_ctx->socket, MTCP_EPOLLIN);
		}

    }
    else {
        scratch->skip_ack_eps = 0;
    }
}

static inline void rto_ep( mtcp_manager_t mtcp, int32_t cur_ts, uint32_t ack_seq, 
    tcp_stream* cur_stream, scratchpad* scratch)
{
    if (scratch->skip_ack_eps) return;

	if (cur_stream->mtp->state != MTP_TCP_ESTABLISHED_ST) return;

    struct mtp_ctx* ctx = cur_stream->mtp;
	
    if(ack_seq < ctx->send_una || ctx->send_next < ack_seq) {
		scratch->skip_ack_eps = 1;
		return;
	}
    
	// MTP TODO: make consistent with MTP
    // Set RTO, using RTT calculation logic from mTCP
	struct tcp_send_vars *sndvar = cur_stream->sndvar;
	struct tcp_recv_vars *rcvvar = cur_stream->rcvvar;
    uint32_t rtt = cur_ts - rcvvar->ts_lastack_rcvd;
	EstimateRTT(mtcp, cur_stream, rtt);
	sndvar->rto = (rcvvar->srtt >> 3) + rcvvar->rttvar;
}

static inline void fast_retr_rec_ep(mtcp_manager_t mtcp, uint32_t cur_ts, uint32_t ack_seq, 
    tcp_stream* cur_stream, scratchpad* scratch)
{
	if(scratch->skip_ack_eps) return;
	if (cur_stream->mtp->state != MTP_TCP_ESTABLISHED_ST) return;
    struct mtp_ctx* ctx = cur_stream->mtp;

	scratch->change_cwnd = 1;

	if(ack_seq == ctx->last_ack) {
		ctx->duplicate_acks++;

		scratch->change_cwnd = 0;

		if(ctx->duplicate_acks == 1) {
			ctx->flightsize_dupl = ctx->send_next - ctx->send_una;
		}

		if(ctx->duplicate_acks == 3) {
			// MTP congestion window resize
            uint32_t opt1 = ctx->flightsize_dupl/2;
            uint32_t opt2 = 2 * ctx->SMSS;
            if (opt1 >= opt2) ctx->ssthresh = opt1;
            else ctx->ssthresh = opt2;
			
            ctx->cwnd_size = ctx->ssthresh + ctx->SMSS;
		}

		if(ctx->duplicate_acks != 3) {
			ctx->cwnd_size += ctx->SMSS;
		}
	} else {
		if(ctx->duplicate_acks > 0) {
			ctx->cwnd_size = ctx->ssthresh;
		}
		ctx->duplicate_acks = 0;
		ctx->last_ack = ack_seq;
	}
}

static inline void slows_congc_ep(mtcp_manager_t mtcp, uint32_t cur_ts, uint32_t ack_seq, 
	tcp_stream* cur_stream, scratchpad* scratch)
{
	if(scratch->skip_ack_eps) return;
	if (cur_stream->mtp->state != MTP_TCP_ESTABLISHED_ST) return;
    struct mtp_ctx *ctx = cur_stream->mtp;

	if(scratch->change_cwnd) {
		uint32_t rmlen = ack_seq - ctx->send_una;
		uint16_t packets = rmlen / ctx->eff_SMSS;
		if (packets * ctx->eff_SMSS > rmlen) {
			packets++;
		}

		if (ctx->cwnd_size < ctx->ssthresh) {
			ctx->cwnd_size += (ctx->SMSS * packets);
		} else {
			uint32_t add_cwnd = packets * ctx->SMSS * ctx->SMSS / ctx->cwnd_size;
			ctx->cwnd_size += add_cwnd;
		}
	}
}

static inline void ack_net_ep(mtcp_manager_t mtcp, uint32_t cur_ts, uint32_t ack_seq, 
	uint32_t window, uint32_t seq, tcp_stream* cur_stream, scratchpad* scratch)
{
	if(scratch->skip_ack_eps) return;
	if (cur_stream->mtp->state != MTP_TCP_ESTABLISHED_ST) return;
    struct mtp_ctx *ctx = cur_stream->mtp;
	struct tcp_send_vars *sndvar = cur_stream->sndvar;
	

	// Update window
	uint32_t rwindow = window << ctx->wscale_remote;
    // MTP TODO: sequence comparisons
    if (TCP_SEQ_LT(ctx->lwu_seq, seq) ||
        (ctx->lwu_seq == seq && TCP_SEQ_LT(ctx->lwu_ack, ack_seq)) ||
        (ctx->lwu_ack == ack_seq && rwindow > ctx->last_rwnd_remote)){
        uint32_t rwindow_prev = ctx->last_rwnd_remote;
        ctx->last_rwnd_remote = rwindow;
        ctx->lwu_seq = seq;
        ctx->lwu_ack = ack_seq;
        if (rwindow_prev < (ctx->send_next - ctx->send_una) &&
            ctx->last_rwnd_remote >= (ctx->send_next - ctx->send_una)){
            // This is kinda "notify" in MTP
            RaiseWriteEvent(mtcp, cur_stream);
        }
    }
 
    // MTP TODO: fix sndbuf->len	
	uint32_t data_rest = ctx->send_una + sndvar->sndbuf->len - ctx->send_next;
	if (data_rest == 0 && ack_seq == ctx->send_next) {
		TimerCancel(mtcp, cur_stream);
		return;
	}

	uint32_t effective_window = ctx->cwnd_size;
    if (ctx->last_rwnd_remote < effective_window){
        effective_window = ctx->last_rwnd_remote;
    }
	
    uint32_t bytes_to_send = 0;

	if(ctx->duplicate_acks == 3) {
		//SBUF_LOCK(&sndvar->write_lock);

		bytes_to_send = ctx->eff_SMSS;
        if (bytes_to_send > effective_window){
            bytes_to_send = effective_window;
        }

        // MTP TODO: check that size + options is not more than MSS
        mtp_bp* bp = GetFreeBP(cur_stream);
        
        memset(&(bp->hdr), 0, sizeof(struct mtp_bp_hdr) + sizeof(struct mtp_bp_options));

        bp->hdr.source = cur_stream->mtp->local_port;
        bp->hdr.dest = cur_stream->mtp->remote_port;
        bp->hdr.seq = htonl(ctx->send_una);
        bp->hdr.ack_seq = htonl(ctx->recv_next);

        bp->hdr.syn = FALSE;
        bp->hdr.ack = FALSE;

        // options to calculate data offset
       
        // MTP TODO: SACK? 
    #if TCP_OPT_SACK_ENABLED
        printf("ERROR:SACK Not supported in MTP TCP\n");
    #endif

        MTP_set_opt_nop(&(bp->opts.nop1));
        MTP_set_opt_nop(&(bp->opts.nop2));

        // MTP TODO: Timestamp
        MTP_set_opt_timestamp(&(bp->opts.timestamp),
                                htonl(cur_ts),
                                htonl(cur_stream->rcvvar->ts_recent));
        
       
        // MTP TODO: would the MTP program do the length 
        //           calculation itself?
        uint16_t optlen = MTP_CalculateOptionLength(bp);
        bp->hdr.doff = (MTP_HEADER_LEN + optlen) >> 2;

        // MTP TODO: wscale on local
        uint8_t wscale = ctx->wscale;
    	uint32_t window32 = ctx->rwnd_size >> wscale;  
		// MTP TODO: fix this
    	uint16_t advertised_window = (uint16_t)MIN(window32, TCP_MAX_WINDOW);
        bp->hdr.window = htons(advertised_window);

        // Payload
        // MTP TODO: fix snbuf
		uint8_t *data = sndvar->sndbuf->head - sndvar->sndbuf->head_seq + ctx->send_una;
        bp->payload.data = data;
        bp->payload.len = bytes_to_send;
        bp->payload.needs_segmentation = FALSE;

        AddtoGenList(mtcp, cur_stream, cur_ts);
		
		//SBUF_UNLOCK(&sndvar->write_lock);
		return;
	}

	// Continue sending if window is available and there's remaining data in sending buffer
	uint32_t window_avail = 0;
	if (ctx->send_una + effective_window > ctx->send_next) 
		window_avail = ctx->send_una + effective_window - ctx->send_next;

	if (window_avail == 0)
		bytes_to_send = 0;
	else {
        if (data_rest < window_avail) bytes_to_send = data_rest;
        else bytes_to_send = window_avail;
    }

    mtp_bp* bp = GetFreeBP(cur_stream);
    
    memset(&(bp->hdr), 0, sizeof(struct mtp_bp_hdr) + sizeof(struct mtp_bp_options));

    bp->hdr.source = cur_stream->mtp->local_port;
    bp->hdr.dest = cur_stream->mtp->remote_port;
    bp->hdr.seq = htonl(ctx->send_next);
    bp->hdr.ack_seq = htonl(ctx->recv_next);

    bp->hdr.syn = FALSE;
    bp->hdr.ack = FALSE;

    // options to calculate data offset
   
    // MTP TODO: SACK? 
#if TCP_OPT_SACK_ENABLED
    printf("ERROR:SACK Not supported in MTP TCP\n");
#endif

    MTP_set_opt_nop(&(bp->opts.nop1));
    MTP_set_opt_nop(&(bp->opts.nop2));

    // MTP TODO: Timestamp
    MTP_set_opt_timestamp(&(bp->opts.timestamp),
                            htonl(cur_ts),
                            htonl(cur_stream->rcvvar->ts_recent));
    
   
    // MTP TODO: would the MTP program do the length 
    //           calculation itself?
    uint16_t optlen = MTP_CalculateOptionLength(bp);
    bp->hdr.doff = (MTP_HEADER_LEN + optlen) >> 2;

    // MTP TODO: wscale on local
    uint32_t window32 = cur_stream->mtp->rwnd_size;
    uint16_t advertised_window = MIN(window32, TCP_MAX_WINDOW);
    bp->hdr.window = htons(advertised_window);

    // Payload
    // MTP TODO: fix snbuf
    uint8_t *data = sndvar->sndbuf->head - sndvar->sndbuf->head_seq + ctx->send_next;
    bp->payload.data = data;
    bp->payload.len = bytes_to_send;
    bp->payload.needs_segmentation = TRUE;
    bp->payload.seg_size = ctx->eff_SMSS;
    bp->payload.seg_rule_group_id = 1; 

    AddtoGenList(mtcp, cur_stream, cur_ts);	

	ctx->send_next += bytes_to_send;

	// Remove acked sequence from sending buffer
	// This step is kinda target dependent (depending on the implementation of sending buffer)
	uint32_t rmlen = ack_seq - ctx->send_una;
	if(rmlen > 0) {
		uint32_t offset = ctx->send_una - ctx->init_seq;
		TxDataFlush(mtcp, cur_stream, offset, rmlen);
		ctx->send_una = ack_seq;
	}

	// MTP TODO: match the mtp file in creating right "event" on timeout
	TimerRestart(mtcp, cur_stream, cur_ts);
}

static inline void data_net_ep(mtcp_manager_t mtcp, uint32_t cur_ts, uint32_t seq, uint8_t *payload,
    int payloadlen, tcp_stream* cur_stream)
{
    struct tcp_recv_vars *rcvvar = cur_stream->rcvvar;
    uint32_t last_rcvd_seq = seq + payloadlen;

	// MTP TODO?: new ordered data

	// if seq and segment length is lower than rcv_nxt or exceeds buffer, ignore and send ack
	if (TCP_SEQ_LT(last_rcvd_seq, cur_stream->rcv_nxt) ||
		TCP_SEQ_GT(last_rcvd_seq, cur_stream->rcv_nxt + rcvvar->rcv_wnd)) {
		return;
	}

	if (SBUF_LOCK(&rcvvar->read_lock)) {
		if (errno == EDEADLK) perror("ProcessTCPPayload: read_lock blocked\n");
		assert(0);
	}

    RBPut(mtcp->rbm_rcv, rcvvar->meta_rwnd, payload, (uint32_t)payloadlen, seq);
	cur_stream->rcv_nxt = rcvvar->meta_rwnd->head_seq + rcvvar->meta_rwnd->merged_len;
    RBRemove(mtcp->rbm_rcv, rcvvar->meta_rwnd, rcvvar->meta_rwnd->merged_len, AT_APP);
	rcvvar->rcv_wnd = rcvvar->rcvbuf->size - (cur_stream->rcv_nxt - 1 - cur_stream->rcvvar->last_flushed_seq);

	SBUF_UNLOCK(&rcvvar->read_lock);

	if (cur_stream->state == TCP_ST_ESTABLISHED) {
		// "add_data_seg" instruction
		RaiseReadEvent(mtcp, cur_stream);
	}
}

inline void send_ack_ep(mtcp_manager_t mtcp, uint32_t cur_ts, tcp_stream *cur_stream)
{
    uint32_t seq = cur_stream->snd_nxt;
    uint32_t ack = cur_stream->rcv_nxt;
    uint32_t window32 = cur_stream->rcvvar->rcv_wnd;
    uint16_t advertised_window = MIN(window32, TCP_MAX_WINDOW);
    SendMTPPacket(mtcp, cur_stream, cur_ts, TCP_FLAG_ACK, 
        seq, ack, advertised_window, NULL, 0);
}

static inline int listen_ep(mtcp_manager_t mtcp, int sockid, int backlog) 
{
	return CreateListenCtx(mtcp, sockid, backlog);
}

static inline struct accept_res* accept_ep(mctx_t mctx, mtcp_manager_t mtcp,
	struct sockaddr *addr, socklen_t *addrlen, struct mtp_listen_ctx *ctx) 
{
	// Wait until a client request to connect
	pthread_mutex_lock(&ctx->accept_lock);
	if (TAILQ_EMPTY(&ctx->pending)) {
		pthread_cond_wait(&ctx->accept_cond, &ctx->accept_lock);// check lock
		if (mtcp->ctx->done || mtcp->ctx->exit) {
			pthread_mutex_unlock(&ctx->accept_lock);
			errno = EINTR;
			return NULL;
		}
	}
	struct accept_res *res = TAILQ_FIRST(&ctx->pending);
	TAILQ_REMOVE(&ctx->pending, res, link);
	ctx->pending_len--;
	pthread_mutex_unlock(&ctx->accept_lock);

	if (ctx->state == 0)
		ctx->state = 1;

	// Return res, let target (api) do the following socket allocation
	return res;
}

static inline void syn_ep(mtcp_manager_t mtcp, uint32_t cur_ts,
	uint32_t ev_remote_ip, uint16_t ev_remote_port, uint32_t ev_init_seq, uint16_t ev_rwnd_size,
    bool ev_sack_permit, bool ev_mss_valid, uint16_t ev_mss, bool ev_wscale_valid, uint8_t ev_wscale,
	struct mtp_listen_ctx *ctx)
{
	if (ctx->state != MTP_TCP_LISTEN_ST) return;
    
    // MTP TODO: do rand init seq
    // uint32_t init_seq = rand_r(&next_seed) % TCP_MAX_SEQ;
    uint32_t init_seq = 0;

    uint8_t wscale = 0;
    if (ev_wscale_valid) wscale = ev_wscale;

    uint16_t mss = 1460;
    if (ev_mss_valid) mss = ev_mss;
	// MTP new_ctx instruction
	tcp_stream *cur_stream = CreateCtx(mtcp, cur_ts, 
                                      ev_remote_ip, ctx->local_ip, 
                                      ev_remote_port, ctx->local_port,
                                      ev_sack_permit, mss, 
                                      init_seq, init_seq, init_seq + 1,
                                      ev_init_seq, ev_init_seq + 1, ev_init_seq,
                                      ev_rwnd_size, wscale,
                                      MTP_TCP_SYNACK_SENT_ST);
	if (cur_stream == NULL) return;

	// Add stream to the listen context
	// Note: since mTCP's accept_res struct includes flow context, we insert
	//		new accept_res after context creation
	pthread_mutex_lock(&ctx->accept_lock);
	if (ctx->pending_len < ctx->pending_cap) {
		struct accept_res *acc = malloc(sizeof(*acc));
		acc->stream = cur_stream;
		TAILQ_INSERT_TAIL(&ctx->pending, acc, link);
		ctx->pending_len++;
	} else {
		// Error handling
		cur_stream->state = TCP_ST_CLOSED;
		cur_stream->close_reason = TCP_NOT_ACCEPTED;
		pthread_mutex_unlock(&ctx->accept_lock);
		return;
	}
	pthread_mutex_unlock(&ctx->accept_lock);

	// MTP pkt gen
	/*uint32_t window32 = cur_stream->rcvvar->rcv_wnd;
	uint16_t advertised_window = MIN(window32, TCP_MAX_WINDOW);

	SendMTPPacket(mtcp, cur_stream, cur_ts,
		TCP_FLAG_SYN | TCP_FLAG_ACK, 
		cur_stream->sndvar->iss, //seq
		init_seq + 1, //ack
		advertised_window, //window
		NULL, 0);
    */
    // MTP TODO: check that size + options is not more than MSS
   
    mtp_bp* bp = GetFreeBP(cur_stream);
    
    memset(&(bp->hdr), 0, sizeof(struct mtp_bp_hdr) + sizeof(struct mtp_bp_options));

	bp->hdr.source = cur_stream->mtp->local_port;
	bp->hdr.dest = cur_stream->mtp->remote_port;
    bp->hdr.seq = htonl(cur_stream->mtp->init_seq);
    bp->hdr.ack_seq = htonl(ev_init_seq + 1);

    bp->hdr.syn = TRUE;
    bp->hdr.ack = TRUE;

    // options to calculate data offset
    // MSS
    MTP_set_opt_mss(&(bp->opts.mss), cur_stream->mtp->SMSS);
   
    // MTP TODO: SACK? 
#if TCP_OPT_SACK_ENABLED
    printf("ERROR:SACK Not supported in MTP TCP\n");
#endif

    MTP_set_opt_nop(&(bp->opts.nop1));
    MTP_set_opt_nop(&(bp->opts.nop2));

    // MTP TODO: Timestamp
    MTP_set_opt_timestamp(&(bp->opts.timestamp),
                            htonl(cur_ts),
                            htonl(cur_stream->rcvvar->ts_recent));
    
    // MTP TODO: Window scale
    MTP_set_opt_nop(&(bp->opts.nop3));
    MTP_set_opt_wscale(&(bp->opts.wscale), cur_stream->mtp->wscale);
   
    // MTP TODO: would the MTP program do the length 
    //           calculation itself?
    uint16_t optlen = MTP_CalculateOptionLength(bp);
    bp->hdr.doff = (MTP_HEADER_LEN + optlen) >> 2;

    uint32_t window32 = cur_stream->mtp->rwnd_size;
	uint16_t advertised_window = MIN(window32, TCP_MAX_WINDOW);
	bp->hdr.window = htons(advertised_window);

    // Payload
    bp->payload.data = NULL;
    bp->payload.len = 0;
    bp->payload.needs_segmentation = FALSE;

    AddtoGenList(mtcp, cur_stream, cur_ts);
}


/***********************************************
 MTP Event Processor Chains
 
 EP chinas are globally exposed
 They implement parts for dispatcher in MTP code
 ***********************************************/
void MtpSendChain(mtcp_manager_t mtcp, uint32_t cur_ts, tcp_stream *cur_stream)
{
	printf("Calling send chain\n");
    send_ep(mtcp, cur_ts, cur_stream);
}

void MtpAckChain(mtcp_manager_t mtcp, uint32_t cur_ts, uint32_t ack_seq, 
    uint32_t window, uint32_t seq, tcp_stream* cur_stream)
{
    /*
    struct tcp_send_vars *sndvar = cur_stream->sndvar;

    if (cur_stream->state == TCP_ST_SYN_RCVD){
		// check if we're processing an acknowledgement of a SYN-ACK
		if (ack_seq != sndvar->iss + 1) {
			CTRACE_ERROR("Stream %d (TCP_ST_SYN_RCVD): "
					"weird ack_seq: %u, iss: %u\n", 
					cur_stream->id, ack_seq, sndvar->iss);
			return;
		}

		TimerCancel(mtcp, cur_stream);
	
		uint32_t prior_cwnd = sndvar->cwnd;
		sndvar->snd_una++;
		cur_stream->snd_nxt = ack_seq;
		sndvar->cwnd = ((prior_cwnd == 1) ? (sndvar->mss * TCP_INIT_CWND): sndvar->mss);
		cur_stream->state = TCP_ST_ESTABLISHED;

		// Raise an event to the listening socket
		struct mtp_listen_ctx *listen_ctx = 
			(struct mtp_listen_ctx *)ListenerHTSearch(mtcp->listeners, &cur_stream->sport);
		if (listen_ctx->socket && (listen_ctx->socket->epoll & MTCP_EPOLLIN)) {
			AddEpollEvent(mtcp->ep, MTCP_EVENT_QUEUE, listen_ctx->socket, MTCP_EPOLLIN);
		}
    } else if(cur_stream->state == TCP_ST_ESTABLISHED) {
    */
    scratchpad scratch;
    conn_ack_ep(mtcp, cur_ts, ack_seq, cur_stream, &scratch);
    rto_ep(mtcp, cur_ts, ack_seq, cur_stream, &scratch);
    fast_retr_rec_ep(mtcp, cur_ts, ack_seq, cur_stream, &scratch);
    slows_congc_ep(mtcp, cur_ts, ack_seq, cur_stream, &scratch);
    ack_net_ep(mtcp, cur_ts, ack_seq, window, seq, cur_stream, &scratch);
}

void MtpDataChain(mtcp_manager_t mtcp, uint32_t cur_ts, uint32_t seq, uint8_t *payload, 
	int payloadlen, tcp_stream *cur_stream)
{
	data_net_ep(mtcp, cur_ts, seq, payload, payloadlen, cur_stream);
    send_ack_ep(mtcp, cur_ts, cur_stream);
}

int MtpListenChain(mtcp_manager_t mtcp, int sockid, int backlog)
{
	return listen_ep(mtcp, sockid, backlog);
}

struct accept_res* MtpAcceptChain(mctx_t mctx, mtcp_manager_t mtcp, struct sockaddr *addr, 
	socklen_t *addrlen, struct mtp_listen_ctx *ctx) 
{
	return accept_ep(mctx, mtcp, addr, addrlen, ctx);
}

void MtpSynChain(mtcp_manager_t mtcp, uint32_t cur_ts,
	uint32_t remote_ip, uint16_t remote_port, uint32_t init_seq, uint16_t rwnd_size,
    bool sack_permit, bool mss_valid, uint16_t mss, bool wscale_valid, uint8_t wscale,
	struct mtp_listen_ctx *ctx) 
{
	syn_ep(mtcp, cur_ts, remote_ip, remote_port, init_seq, rwnd_size, 
           sack_permit, mss_valid, mss, wscale_valid, wscale, ctx);
}
